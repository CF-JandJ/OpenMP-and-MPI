[toc]

# 1. 消息传递编程接口MPI

## 通信子

MIP的通信要在通信子中进行，开始时均被认为在通信子`MPI_COMM_WORLD`中

![image.png](https://note.youdao.com/yws/res/33790/WEBRESOURCEee96a23401b3d9ddd223c6850fa9488e)

## 并行环境函数（开启/关闭）

`MPI_Init()`和`MPI_Finalize()`

- `MPI_Init()`

```cpp
int MPIAPI MPI_Init(
  _In_opt_ int                        *argc,
           _In_opt_count_(*argc) char ***argv
);
```

1. **单线程执行初始化调用 MPI 进程的执行环境**
2. 接受主程序main中的参数`argc,argv`，可传入每个进程中
3. 成功返回`MPI_SUCCESS`,失败返回其他错误代码

> 如果不清楚是否初始化，可用`MPI_Initialized()`函数检查

> 查看出何种错误 可用`MPI_Error_string(int errorcode,char* string,int *len)`检测

参数说明：
`IN errorconde` : `MPI`函数返回的错误码
`OUT string` : 对应错误码的错误信息
`OUT LEN` : STRING的长度 最小为`MPI_MAX_ERROR_STRING`

- `MPI_Finalize(void)`

1. **清除`MPI`环境的所有状态**

## MPI进程控制函数

### 基础知识

`group`是一组有序进程的集合，每个进程都和`rank`相关联，`communicator`包含一组可以互相通信的进程。`communicator`可以看做一个额外的标记，必须包含在`mpi`的调用中

**`group`和`communicator`是一体的，`group routines`主要用于指定使用哪些进程来构造`communicator`**

`group`：`communicator`中所有进程的集合

### MPI进程组操作函数

- `MPI_Comm_group()`

```cpp
int MPIAPI MPI_Comm_group(
        MPI_Comm  comm,
  _Out_ MPI_Group *group
);
```

1. **用来建立一个通信子`comm`对应的新进程组`group`**

- `MPI_GROUP_FREE()`

```cpp
int MPIAPI MPI_Group_free(
   _Inout_ MPI_Group *group // 释放进程组并返回MPI_GROUP_NULL
);
```

1. **任何关于此进程组的操作将视为无效**

- `MPI_Group_size()`

```cpp
int MPIAPI MPI_Group_size(
        MPI_Group group, // 进程组
  _Out_ int       *size  // 进程组中的进程个数
);
```
1. **进程组中的个数**

- `MPI_Group_rank()`

```cpp
int MPIAPI MPI_Group_rank(
        MPI_Group group, // 进程组
  _Out_ int       *rank  // 进程在进程组中的编号
);
```

1. **进程在进程组中的编号**
2. 如果不是进程组中的成员，返回`MPI_UNDEFINED`

- `MPI_Group_translate_ranks()`

```cpp
int MPIAPI MPI_Group_translate_ranks(
        MPI_Group         group1, // 进程组1
        int               n,      // 参数数组 ranks1和 ranks2中个数
        _In_count_(n) int *ranks1,// 进程组1中有效编号组成的数组
        MPI_Group         group2, // 进程组2
  _Out_ int               *ranks2 // RANKS1中的元素在进程组2中的对应编号
);
```

1. **在两个不同的组中确定相同进程的相对编号**
2. 值`MPI _ UNDEFINED`表示进程在第一组中，但不在第二组中

- `MPI_Group_incl()`

```cpp
int MPIAPI MPI_Group_incl(
        MPI_Group         group,    // 进程组
        int               n,        // RANKS数组中元素的个数和新进程组的大小
        _In_count_(n) int *ranks,   // 将在新进程中出现的旧进程组中的编号
  _Out_ MPI_Group         *newgroup // 由RANKS 定义的顺序导出的新进程组
);
```

1. **创建新进程组，由原进程组内RANKS包含的n个进程组成**

- `MPI_Group_excl()`

```cpp
int MPIAPI MPI_Group_excl(
        MPI_Group         group,    // 进程组
        int               n,        // RANKS数组中元素的个数
        _In_count_(n) int *ranks,   // 在新进程组中不出现的旧进程组中的编号
  _Out_ MPI_Group         *newgroup // 旧进程组中不在RANKS里的元素组成的新进程组
);
```

1. **创建新进程组，由原进程组内除了RANKS包含的n个进程以外的进程组成**

举例：
```
group = {a,b,c,d,e,f,g,h,i,j}
n = 5 , ranks = {0,3,8,6,2}

MPI_Group_incl(group,n,ranks,newgroup);
newgroup = {a,d,i,g,c}
MPI_Group_excl(group,n,ranks,newgroup);
newgroup = {b,e,f,h,j}
```

- `MPI_Group_union()`

```cpp
int MPIAPI MPI_Group_union(
        MPI_Group group1,   //进程组1
        MPI_Group group2,   //进程组2
  _Out_ MPI_Group *newgroup //进程组1和进程组2的合并
);
```

1. **实现进程组并功能**

- `MPI_Group_intersection()`

```cpp
int MPIAPI MPI_Group_intersection(
        MPI_Group group1,
        MPI_Group group2,
  _Out_ MPI_Group *newgroup
);
```

1. **实现进程组交功能**

- `MPI_Group_difference()`

```cpp
int MPIAPI MPI_Group_difference(
        MPI_Group group1,
        MPI_Group group2,
  _Out_ MPI_Group *newgroup
);
```

1. **实现进程组差功能**

### MPI通信子操作

- `MPI_Comm_size()`

```cpp
int MPIAPI MPI_Comm_size(
        MPI_Comm comm,  // 通信子
  _Out_ int      *size  // 通信子中的进程个数
);
```

1. **获得通信子中进程的个数**

- `MPI_Comm_rank()`

```cpp
int MPIAPI MPI_Comm_rank(
        MPI_Comm comm,  // 通信子
  _Out_ int      *rank  // 通信子中的进程编号
);
```

1. **获得通信子的进程编号**

- `MPI_Comm_dup()`

```cpp
int MPIAPI MPI_Comm_dup(
        MPI_Comm comm,    // 通信子
  _Out_ MPI_Comm *newcomm // COMM副本
);
```

1. **复制通信子**
2. 这对于使用库执行特殊函数的应用（例如数学库）非常有用,在这类应用中，重要的是用户代码和库代码不要互相干扰。 为了避免这种情况，每个应用程序应该做的第一件事是创建 `MPI_COMM_WORLD` 的副本，这将避免其他使用 `MPI_COMM_WORLD` 的库的问题。 库本身也应该复制 `MPI_COMM_WORLD` 以避免相同的问题

- `MPI_Comm_create()`

```cpp
int MPIAPI MPI_Comm_create(
        MPI_Comm  comm,     // 通信子
        MPI_Group group,    // 通信子COMM的一个字集
  _Out_ MPI_Comm  *newcomm  // 对应GROUP的新通信子
);
```

1. **GROUP中所有进程都关联到同一个通信子中，GROUP以外的进程将返回MPI_COMM_NULL进程组**
2. `MPI_Comm_create_group` 仅是 `group` 中包含的一组进程的集合，而 `MPI_Comm_create` 是 `comm` 中每个进程的集合 (`group`有很多组，一个是其中一组，一个是全部组)

- `MPI_Comm_create_group()`

```cpp
MPI_Comm_create_group(
	MPI_Comm comm,
	MPI_Group group,
	int tag,
	MPI_Comm* newcomm)
```

1. 使用一个 `MPI_Group` 对象并创建一个与组具有相同进程的新`comm`

- `MPI_Comm_split()`

```cpp
MPI_Comm_split(
	MPI_Comm comm,      // 通信子
	int color,          // 子集控制器
	int key,            // 子集中进程编号的顺序
	MPI_Comm* newcomm)  // 由此产生的新通信子
```

1. **创建新的通信子**
2. `MPI_Comm_split` 通过基于输入值 `color` 和 `key` 将`comm`“拆分”为一组子`comm`来创建新的`comm`
3. 原始的`comm`并没有消失，但是在每个进程中都会创建一个新的`comm`
4. 如果 `color` 为 `MPI_UNDEFINED`，则该进程将不包含在任何新的`comm`中
5. `key`确定每个新通讯器中的顺序,如果存在平局，则在原始通讯器中秩较低的进程将是第一位

- `MPI_Comm_free()`

```cpp
int MPIAPI MPI_Comm_free(
   _Inout_ MPI_Comm *comm
);
```

1. **释放一个通信子**

#### 实例

> `group`和`comm`的使用

```cpp
// 获取原始通讯器的等级和大小
int world_rank, world_size;
MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);
MPI_Comm_size(MPI_COMM_WORLD, &world_size);

// 获取 MPI_COMM_WORLD 中的进程组
MPI_Group world_group;
MPI_Comm_group(MPI_COMM_WORLD, &world_group);

int n = 7;
const int ranks[7] = {1, 2, 3, 5, 7, 11, 13};

// 构造一个包含 world_group 中所有主要秩的组
MPI_Group prime_group;
MPI_Group_incl(world_group, 7, ranks, &prime_group);

// 根据组创建一个新的通讯器
MPI_Comm prime_comm;
MPI_Comm_create_group(MPI_COMM_WORLD, prime_group, 0, &prime_comm);

int prime_rank = -1, prime_size = -1;
// 如果此秩不在新的通讯器中，则为
// MPI_COMM_NULL。使用 MPI_COMM_NULL 作为 MPI_Comm_rank 或
// MPI_Comm_size 的错误
if (MPI_COMM_NULL != prime_comm) {
	MPI_Comm_rank(prime_comm, &prime_rank);
	MPI_Comm_size(prime_comm, &prime_size);
}

printf("WORLD RANK/SIZE: %d/%d \t PRIME RANK/SIZE: %d/%d\n",
	world_rank, world_size, prime_rank, prime_size);

MPI_Group_free(&world_group);
MPI_Group_free(&prime_group);
MPI_Comm_free(&prime_comm);
```

> 在逻辑上将原始通讯器布局为共 16 个进程的 4x4 网格，并且希望按行划分网格

![](https://mpitutorial.com/tutorials/introduction-to-groups-and-communicators/comm_split.png)

（此时`MPI_COMM_WORLD`有四个组）

```cpp
// 获取原始通讯器的秩和大小
int world_rank, world_size;
MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);
MPI_Comm_size(MPI_COMM_WORLD, &world_size);

int color = world_rank / 4; // 根据行确定颜色

// 根据颜色拆分通讯器，然后调用
// 利用原始秩
MPI_Comm row_comm;
MPI_Comm_split(MPI_COMM_WORLD, color, world_rank, &row_comm);

int row_rank, row_size;
MPI_Comm_rank(row_comm, &row_rank);
MPI_Comm_size(row_comm, &row_size);

printf("WORLD RANK/SIZE: %d/%d \t ROW RANK/SIZE: %d/%d\n",
	world_rank, world_size, row_rank, row_size);

MPI_Comm_free(&row_comm);
```

- 结果

```
WORLD RANK/SIZE: 0/16 	 ROW RANK/SIZE: 0/4
WORLD RANK/SIZE: 1/16 	 ROW RANK/SIZE: 1/4
WORLD RANK/SIZE: 2/16 	 ROW RANK/SIZE: 2/4
WORLD RANK/SIZE: 3/16 	 ROW RANK/SIZE: 3/4
WORLD RANK/SIZE: 4/16 	 ROW RANK/SIZE: 0/4
WORLD RANK/SIZE: 5/16 	 ROW RANK/SIZE: 1/4
WORLD RANK/SIZE: 6/16 	 ROW RANK/SIZE: 2/4
WORLD RANK/SIZE: 7/16 	 ROW RANK/SIZE: 3/4
WORLD RANK/SIZE: 8/16 	 ROW RANK/SIZE: 0/4
WORLD RANK/SIZE: 9/16 	 ROW RANK/SIZE: 1/4
WORLD RANK/SIZE: 10/16 	 ROW RANK/SIZE: 2/4
WORLD RANK/SIZE: 11/16 	 ROW RANK/SIZE: 3/4
WORLD RANK/SIZE: 12/16 	 ROW RANK/SIZE: 0/4
WORLD RANK/SIZE: 13/16 	 ROW RANK/SIZE: 1/4
WORLD RANK/SIZE: 14/16 	 ROW RANK/SIZE: 2/4
WORLD RANK/SIZE: 15/16 	 ROW RANK/SIZE: 3/4
```



> 为单独的共同`communications`交换创建两个不同的进程组`group`。也需要创建新的`communicators`

```cpp
#include "mpi.h"
#include <stdio.h>
#define NPROCS 8

main(int argc, char *argv[])  {
int        rank, new_rank, sendbuf, recvbuf, numtasks,
            ranks1[4]={0,1,2,3}, ranks2[4]={4,5,6,7};
MPI_Group  orig_group, new_group;   // required variables
MPI_Comm   new_comm;   // required variable

MPI_Init(&argc,&argv);
MPI_Comm_rank(MPI_COMM_WORLD, &rank);
MPI_Comm_size(MPI_COMM_WORLD, &numtasks);

if (numtasks != NPROCS) {
    printf("Must specify MP_PROCS= %d. Terminating.\n",NPROCS);
    MPI_Finalize();
    exit(0);
    }

sendbuf = rank;

// extract the original group handle
MPI_Comm_group(MPI_COMM_WORLD, &orig_group);

//  divide tasks into two distinct groups based upon rank
if (rank < NPROCS/2) {
    MPI_Group_incl(orig_group, NPROCS/2, ranks1, &new_group);
    }
else {
    MPI_Group_incl(orig_group, NPROCS/2, ranks2, &new_group);
    }

// create new new communicator and then perform collective communications
MPI_Comm_create(MPI_COMM_WORLD, new_group, &new_comm);
MPI_Allreduce(&sendbuf, &recvbuf, 1, MPI_INT, MPI_SUM, new_comm);

// get rank in new group
MPI_Group_rank (new_group, &new_rank);
printf("rank= %d newrank= %d recvbuf= %d\n",rank,new_rank,recvbuf);

MPI_Finalize();
}
```

## 点到点通信函数



## 实例

> 说明

进行一个矩阵运算，`y = A*x`，其中：`A = m*n, x = n*1 , y = m*1`

> 大致步骤

1. 把矩阵`A`分割后发送到其他进程：`Send,Recv`
2. 把`x`广播到各个进程：`Bcast`
3. 计算每个进程上的矩阵块与向量乘积：`yi`
4. 从各个进程收集结果组装到`y`：`MPI_Gatter`

```cpp
// MPI_test

#include <iostream>
#include <mpi.h>
#include <cassert>
#include <chrono>
#include <Windows.h>

using namespace std;

int main(int argc,char** argv){
    
    const int N = 16; // 矩阵的行列数
	const int root = 0;// 根进程编号
	
	//Sleep(100000);

	// 1. 初始化MPI
	int ret = MPI_Init(&argc, &argv);
	assert(ret == MPI_SUCCESS);// 验证调用是否成功

	int rank{ 0 }, np{ 0 };
	MPI_Comm_size(MPI_COMM_WORLD, &np);
	MPI_Comm_rank(MPI_COMM_WORLD, &rank);

	assert(N % np == 0); // 任务能够分割成相等的份数

	int m = N / np; // 每个进程上分配的行数

	// 2.把根进程上的矩阵分割并发送到各个进程
	
	double Ai[4][N]{ 0 };
	double yi[4]{ 0 };
	double x[N]{ 0 };
	assert(m <= 4);

	// 当前进程是根进程
	if (rank == root) {
		double A[N][N]{ 0 };
		for (int i = 0; i < N; ++i) {
			for (int j = 0; j < N; ++j) {
				A[i][j] = i * N + j;
			}
		}
		for (int i = 0; i < N; ++i) {
			x[i] = i;
		}

		// 发送数据
		// 分割：进程i 对应于 i*m <-> (i+1)*m-1
		for (int dest = 0; dest < np; ++dest) {
			if (dest != rank) {
				MPI_Send(&A[dest * m][0], N * m, MPI_DOUBLE, dest, 0, MPI_COMM_WORLD);
			}
			else {
				std::memcpy(&Ai[0][0], &A[dest * m][0], sizeof(double) * N * m);
			}
		}
	}
	// 当前进程是其他进程
	else {
		MPI_Status status;
		MPI_Recv(&Ai[0][0], N * m, MPI_DOUBLE, root, 0, MPI_COMM_WORLD, &status);
	}

	// 3. 广播 x
	MPI_Bcast(&x[0], N, MPI_DOUBLE, root, MPI_COMM_WORLD);
	
	// 4. 计算各个矩阵块与向量的乘积
	for (int i = 0; i < m; ++i) {
		yi[i] = 0;
		for (int j = 0; j < N; ++j) {
			yi[i] += Ai[i][j] * x[j];
		} 
	}

	MPI_Barrier(MPI_COMM_WORLD);

	// 5. 从各个进程收集结果到根进程中
	double y[N]{ 0 };
	
	// 没有把根进程的yi 收集到 y 中
	MPI_Gather(&yi[0], m, MPI_DOUBLE, &y[0], m, MPI_DOUBLE, root, MPI_COMM_WORLD);
	if (rank == root) {
		std::memcpy(&y[rank * m], &yi[0], sizeof(double) * m);
	}

	if (rank == root) {
		for (int i = 0; i < N; ++i) {
			std::cout << y[i] << std::endl;
		}
	}

	// 退出MPI环境
	MPI_Finalize();
    
    return 0;
}

```

> 结果

![image.png](https://note.youdao.com/yws/res/33406/WEBRESOURCE585b472c0beb2406bf8edb8cd1ef9653)

> 如何调试MPI

首先添加`sleep`函数，命令行执行，在调试->附加到进程中选中相应的进程，从而进行调试

![image.png](https://note.youdao.com/yws/res/33402/WEBRESOURCE4f284969d026800b3f50030b6de301e4)

![image.png](https://note.youdao.com/yws/res/33404/WEBRESOURCE2cafa784bc6e7df69a5e7bc987d2c8f0)


# 5. 共享存储并行编程OpenMP

## 实例

> 说明

有`a`,`b`两个数组，`c`数组等于`a`、`b`数组对应元素运算结果

> 代码

```cpp
// OpenMP_test

#include <iostream>
#include <chrono>
#include <omp.h>
#include <vector>
#include <cassert>
#include <cmath>

int main(){
    const int N = 200000000;

	std::vector<double> a(N), b(N), c(N), d(N);

	// 设置数组a,b
	for (int i = 0; i < N; ++i) {
		a[i] = 2 * i + 1;
		b[i] = 2 * i;
	}

	auto t0 = omp_get_wtime();
	// 串行计算
	for (int i = 0; i < N; ++i) {
		c[i] = std::sin(a[i]) + std::cos(b[i]);
	}

	auto t1 = omp_get_wtime();

	std::cout<< "串行计算的时间为：" << t1 - t0 << std::endl;
	
	omp_set_num_threads(8);

	auto t2 = omp_get_wtime();
	
	// 使用OpenMP并行
//#pragma omp parallel for default(none) shared(a,b,d)
// 	for (int i = 0; i < N; ++i) {
//		d[i] = a[i] + b[i];
//	}

#pragma omp parallel
	{
		int nt = omp_get_num_threads();
		int it = omp_get_thread_num();
		
		assert(N % nt == 0);
		int m = N / nt;
		
#pragma omp master
		{
			printf("num thread = %d\n", nt);
		}
		
		// it*m -> (it+1)*m-1
		for (int i = it * m; i < (it + 1) * m; ++i) {
			d[i] = std::sin(a[i]) + std::cos(b[i]);
		}
	}

	auto t3 = omp_get_wtime();
	std::cout << "并行计算的时间为：" << t3 - t2 << std::endl;
	
	return 0;
}

```

> 结果

![image.png](https://note.youdao.com/yws/res/33431/WEBRESOURCE39bff9f09f1d6e55c52a8d875a8c5b8b)

> 说明

求出数组最大值的位置及其元素

> 代码

```cpp
#include <iostream>
#include <chrono>
#include <omp.h>
#include <vector>
#include <cassert>
#include <cmath>

int main(){
    const int N = 24000000;

	std::vector<double> a(N);

	time_t seed = time(0);
	srand(seed);
	// 设置数组a,b
	for (int i = 0; i < N; ++i) {
		a[i] = rand();
	}

	double vmax{ a[0]};
	int    vloc{ 0 };

	auto t0 = omp_get_wtime();
	// 串行计算
	for (int i = 0; i < N; ++i) {
		if (a[i] > vmax) {
			vmax = a[i];
			vloc = i;
		}
	}

	auto t1 = omp_get_wtime();

	std::cout << "串行计算的时间为：" << t1 - t0 << std::endl;
	std::cout << "serial:max = " << vmax << ", vloc = " << vloc << std::endl;

	vmax = a[0];vloc = 0;
	t0 = omp_get_wtime();
	//方法1 注意如果没有加 #pragma omp critical ，直接并行计算，会访问冲突
#pragma omp parallel for
	for (int i = 0; i < N; ++i) {
		if (a[i] > vmax) {
#pragma omp critical
			{
				if (a[i] > vmax) {
					vmax = a[i];
					vloc = i;
				}
			}
		}
	}

	t1 = omp_get_wtime();
	std::cout << "方法1:并行计算的时间为：" << t1 - t0 << std::endl;
	std::cout << "serial:max = " << vmax << ", vloc = " << vloc << std::endl;


	//方法2
	vmax = a[0]; vloc = 0;
	t0 = omp_get_wtime();
#pragma omp parallel
	{
		int nt = omp_get_num_threads();
		int it = omp_get_thread_num();
		assert(N % nt == 0);
		int m = N / nt;
		
		// 找出当前线程对应部分的最大值及位置
		double vmax_i{ a[it * m] };
		int    vloc_i{ it * m };
		for (int i = it * m; i < (it + 1) * m; ++i) {
			if (a[i] > vmax_i) {
				vmax_i = a[i];
				vloc_i = i;
			}
		}

		// 串行获取所有的最大值
#pragma omp critical
		{
			if (vmax_i > vmax) {
				vmax = vmax_i;
				vloc = vloc_i;
			}
		}
	}

	t1 = omp_get_wtime();
	std::cout << "方法2：并行计算的时间为：" << t1 - t0 << std::endl;
	std::cout << "serial:max = " << vmax << ", vloc = " << vloc << std::endl;

	//方法3
	vmax = a[0]; vloc = 0;
	t0 = omp_get_wtime();
	double vmax_t[24]{ 0 }, vloc_t[24]{ 0 };
#pragma omp parallel for 
	for (int i = 0; i < N; ++i) {
		int id = omp_get_thread_num();
		if (a[i] > vmax_t[id]) {
			vmax_t[id] = a[i]; //? 不存在访问冲突
			vloc_t[id] = i;    //? 不存在访问冲突
		}
	}
	
	// 串行获取最大值
	for (int i = 0; i < 24; ++i) {
		if (vmax_t[i] > vmax) {
			vmax = vmax_t[i];
			vloc = vloc_t[i];
		}
	}
	t1 = omp_get_wtime();
	std::cout << "方法3：并行计算的时间为：" << t1 - t0 << std::endl;
	std::cout << "serial:max = " << vmax << ", vloc = " << vloc << std::endl;

    
    return 0;
}
```

> 结果

![image.png](https://note.youdao.com/yws/res/33500/WEBRESOURCEc72b6f766baabe5b9d3e6a967a7ef32c)

注意有相同元素，所以位置找的不同

